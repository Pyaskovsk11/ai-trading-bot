#!/usr/bin/env python3
"""
ML Prediction Service - –°–µ—Ä–≤–∏—Å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ü–µ–Ω
"""

import logging
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime, timedelta
import asyncio
from dataclasses import dataclass
from enum import Enum

# ML –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
try:
    from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
    from sklearn.linear_model import LinearRegression
    from sklearn.preprocessing import StandardScaler, MinMaxScaler
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
    import joblib
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False

logger = logging.getLogger(__name__)

class PredictionModel(Enum):
    """–¢–∏–ø—ã –º–æ–¥–µ–ª–µ–π –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"""
    LINEAR_REGRESSION = "linear_regression"
    RANDOM_FOREST = "random_forest"
    GRADIENT_BOOSTING = "gradient_boosting"
    ENSEMBLE = "ensemble"

class PredictionHorizon(Enum):
    """–ì–æ—Ä–∏–∑–æ–Ω—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"""
    SHORT_TERM = "5m"    # 5 –º–∏–Ω—É—Ç
    MEDIUM_TERM = "1h"   # 1 —á–∞—Å
    LONG_TERM = "4h"     # 4 —á–∞—Å–∞

@dataclass
class PredictionResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"""
    symbol: str
    current_price: float
    predicted_price: float
    confidence: float
    direction: str  # 'up', 'down', 'sideways'
    change_pct: float
    horizon: str
    timestamp: datetime
    features_used: List[str]

@dataclass
class ModelMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏"""
    mse: float
    mae: float
    r2_score: float
    accuracy: float
    precision: float
    recall: float

class MLPredictionService:
    """
    –°–µ—Ä–≤–∏—Å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ü–µ–Ω
    """
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.feature_columns = []
        self.is_trained = False
        
        if not ML_AVAILABLE:
            logger.warning("ML –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è.")
        
        logger.info("MLPredictionService –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def _create_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è ML –º–æ–¥–µ–ª–∏"""
        features_df = df.copy()
        
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        # RSI
        delta = features_df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        features_df['rsi'] = 100 - (100 / (1 + rs))
        
        # MACD
        ema_12 = features_df['close'].ewm(span=12).mean()
        ema_26 = features_df['close'].ewm(span=26).mean()
        features_df['macd'] = ema_12 - ema_26
        features_df['macd_signal'] = features_df['macd'].ewm(span=9).mean()
        features_df['macd_histogram'] = features_df['macd'] - features_df['macd_signal']
        
        # Bollinger Bands
        bb_period = 20
        bb_middle = features_df['close'].rolling(bb_period).mean()
        bb_std = features_df['close'].rolling(bb_period).std()
        features_df['bb_upper'] = bb_middle + (bb_std * 2)
        features_df['bb_lower'] = bb_middle - (bb_std * 2)
        features_df['bb_width'] = (features_df['bb_upper'] - features_df['bb_lower']) / bb_middle
        features_df['bb_position'] = (features_df['close'] - features_df['bb_lower']) / (features_df['bb_upper'] - features_df['bb_lower'])
        
        # –°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ
        for period in [5, 10, 20, 50]:
            features_df[f'sma_{period}'] = features_df['close'].rolling(period).mean()
            features_df[f'ema_{period}'] = features_df['close'].ewm(span=period).mean()
            features_df[f'price_to_sma_{period}'] = features_df['close'] / features_df[f'sma_{period}']
        
        # –¶–µ–Ω–æ–≤—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
        for period in [1, 3, 5, 10]:
            features_df[f'return_{period}'] = features_df['close'].pct_change(period)
            features_df[f'high_low_ratio_{period}'] = (features_df['high'] - features_df['low']) / features_df['close']
        
        # –û–±—ä–µ–º–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        features_df['volume_sma'] = features_df['volume'].rolling(20).mean()
        features_df['volume_ratio'] = features_df['volume'] / features_df['volume_sma']
        features_df['price_volume'] = features_df['close'] * features_df['volume']
        
        # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
        features_df['volatility_5'] = features_df['close'].pct_change().rolling(5).std()
        features_df['volatility_20'] = features_df['close'].pct_change().rolling(20).std()
        
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        features_df['hour'] = features_df.index.hour
        features_df['day_of_week'] = features_df.index.dayofweek
        features_df['month'] = features_df.index.month
        
        # –õ–∞–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        for lag in [1, 2, 3, 5]:
            features_df[f'close_lag_{lag}'] = features_df['close'].shift(lag)
            features_df[f'volume_lag_{lag}'] = features_df['volume'].shift(lag)
        
        return features_df
    
    def _prepare_training_data(self, df: pd.DataFrame, horizon: str = "1h") -> Tuple[np.ndarray, np.ndarray]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        features_df = self._create_features(df)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        horizon_map = {"5m": 1, "1h": 12, "4h": 48}  # –¥–ª—è 5-–º–∏–Ω—É—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        shift_periods = horizon_map.get(horizon, 12)
        
        # –°–æ–∑–¥–∞–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é (–±—É–¥—É—â–∞—è —Ü–µ–Ω–∞)
        features_df['target'] = features_df['close'].shift(-shift_periods)
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å NaN
        features_df = features_df.dropna()
        
        # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–∏
        feature_columns = [col for col in features_df.columns 
                          if col not in ['open', 'high', 'low', 'close', 'volume', 'target', 'timestamp']]
        
        self.feature_columns = feature_columns
        
        X = features_df[feature_columns].values
        y = features_df['target'].values
        
        return X, y
    
    async def train_models(self, historical_data: Dict[str, pd.DataFrame], horizon: str = "1h") -> Dict[str, ModelMetrics]:
        """–û–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–µ–π"""
        if not ML_AVAILABLE:
            logger.warning("ML –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ.")
            return {}
        
        logger.info(f"ü§ñ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–µ–π –¥–ª—è –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞ {horizon}")
        
        all_metrics = {}
        
        for symbol, df in historical_data.items():
            if len(df) < 200:  # –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö
                logger.warning(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è {symbol}: {len(df)} —Å—Ç—Ä–æ–∫")
                continue
            
            try:
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                X, y = self._prepare_training_data(df, horizon)
                
                if len(X) < 100:
                    logger.warning(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}: {len(X)} —Å—Ç—Ä–æ–∫")
                    continue
                
                # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.2, random_state=42, shuffle=False
                )
                
                # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
                scaler = StandardScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_test_scaled = scaler.transform(X_test)
                
                # –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª–∏
                models = {
                    'linear_regression': LinearRegression(),
                    'random_forest': RandomForestRegressor(n_estimators=100, random_state=42),
                    'gradient_boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)
                }
                
                symbol_models = {}
                symbol_metrics = {}
                
                for model_name, model in models.items():
                    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
                    if model_name == 'linear_regression':
                        model.fit(X_train_scaled, y_train)
                        y_pred = model.predict(X_test_scaled)
                    else:
                        model.fit(X_train, y_train)
                        y_pred = model.predict(X_test)
                    
                    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
                    mse = mean_squared_error(y_test, y_pred)
                    mae = mean_absolute_error(y_test, y_pred)
                    r2 = r2_score(y_test, y_pred)
                    
                    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
                    direction_actual = np.sign(y_test - X_test[:, self.feature_columns.index('close_lag_1')])
                    direction_pred = np.sign(y_pred - X_test[:, self.feature_columns.index('close_lag_1')])
                    accuracy = np.mean(direction_actual == direction_pred)
                    
                    metrics = ModelMetrics(
                        mse=mse, mae=mae, r2_score=r2, 
                        accuracy=accuracy, precision=0.0, recall=0.0
                    )
                    
                    symbol_models[model_name] = model
                    symbol_metrics[model_name] = metrics
                    
                    logger.info(f"   {symbol} {model_name}: R¬≤={r2:.3f}, Accuracy={accuracy:.3f}")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª–∏ –∏ —Å–∫–µ–π–ª–µ—Ä
                self.models[symbol] = symbol_models
                self.scalers[symbol] = scaler
                all_metrics[symbol] = symbol_metrics
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è {symbol}: {e}")
        
        self.is_trained = len(self.models) > 0
        logger.info(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ú–æ–¥–µ–ª–∏ –¥–ª—è {len(self.models)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        return all_metrics
    
    async def predict_price(self, symbol: str, current_data: pd.DataFrame, horizon: str = "1h") -> Optional[PredictionResult]:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ü–µ–Ω—ã –¥–ª—è —Å–∏–º–≤–æ–ª–∞"""
        if not self.is_trained or symbol not in self.models:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–µ–Ω–¥–æ–≤
            return self._simple_prediction(symbol, current_data, horizon)
        
        if not ML_AVAILABLE:
            return self._simple_prediction(symbol, current_data, horizon)
        
        try:
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
            features_df = self._create_features(current_data)
            
            if len(features_df) == 0:
                return None
            
            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É
            latest_features = features_df[self.feature_columns].iloc[-1:].values
            
            # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
            scaler = self.scalers[symbol]
            latest_features_scaled = scaler.transform(latest_features)
            
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ—Ç –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
            models = self.models[symbol]
            predictions = []
            
            for model_name, model in models.items():
                if model_name == 'linear_regression':
                    pred = model.predict(latest_features_scaled)[0]
                else:
                    pred = model.predict(latest_features)[0]
                predictions.append(pred)
            
            # –ê–Ω—Å–∞–º–±–ª–µ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (—Å—Ä–µ–¥–Ω–µ–µ)
            predicted_price = np.mean(predictions)
            current_price = current_data['close'].iloc[-1]
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π
            prediction_std = np.std(predictions)
            confidence = max(0.1, 1.0 - (prediction_std / current_price))
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
            change_pct = (predicted_price - current_price) / current_price * 100
            
            if abs(change_pct) < 0.1:
                direction = 'sideways'
            elif change_pct > 0:
                direction = 'up'
            else:
                direction = 'down'
            
            return PredictionResult(
                symbol=symbol,
                current_price=current_price,
                predicted_price=predicted_price,
                confidence=confidence,
                direction=direction,
                change_pct=change_pct,
                horizon=horizon,
                timestamp=datetime.now(),
                features_used=self.feature_columns
            )
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è {symbol}: {e}")
            return self._simple_prediction(symbol, current_data, horizon)
    
    def _simple_prediction(self, symbol: str, current_data: pd.DataFrame, horizon: str) -> PredictionResult:
        """–ü—Ä–æ—Å—Ç–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–µ–Ω–¥–æ–≤"""
        if len(current_data) < 20:
            return None
        
        current_price = current_data['close'].iloc[-1]
        
        # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞
        short_ma = current_data['close'].rolling(5).mean().iloc[-1]
        long_ma = current_data['close'].rolling(20).mean().iloc[-1]
        
        # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
        volatility = current_data['close'].pct_change().rolling(10).std().iloc[-1]
        
        # –ü—Ä–æ—Å—Ç–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–µ–Ω–¥–∞
        if short_ma > long_ma:
            # –í–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥
            predicted_change = volatility * 0.5  # 50% –æ—Ç –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
            direction = 'up'
        elif short_ma < long_ma:
            # –ù–∏—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥
            predicted_change = -volatility * 0.5
            direction = 'down'
        else:
            # –ë–æ–∫–æ–≤–æ–π —Ç—Ä–µ–Ω–¥
            predicted_change = 0
            direction = 'sideways'
        
        predicted_price = current_price * (1 + predicted_change)
        change_pct = predicted_change * 100
        confidence = 0.3  # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        
        return PredictionResult(
            symbol=symbol,
            current_price=current_price,
            predicted_price=predicted_price,
            confidence=confidence,
            direction=direction,
            change_pct=change_pct,
            horizon=horizon,
            timestamp=datetime.now(),
            features_used=['simple_trend_analysis']
        )
    
    async def get_trading_signals(self, predictions: List[PredictionResult], min_confidence: float = 0.6) -> List[Dict]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
        signals = []
        
        for pred in predictions:
            if pred.confidence < min_confidence:
                continue
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∏–ª—É —Å–∏–≥–Ω–∞–ª–∞
            signal_strength = abs(pred.change_pct) * pred.confidence
            
            if signal_strength < 0.5:  # –°–ª–∞–±—ã–π —Å–∏–≥–Ω–∞–ª
                continue
            
            signal = {
                'symbol': pred.symbol,
                'signal': 'buy' if pred.direction == 'up' else 'sell' if pred.direction == 'down' else 'hold',
                'confidence': pred.confidence,
                'predicted_change': pred.change_pct,
                'horizon': pred.horizon,
                'strategy_type': 'ml_prediction',
                'reason': f"ML –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {pred.direction} –Ω–∞ {pred.change_pct:.2f}% (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {pred.confidence:.2f})",
                'should_execute': signal_strength > 1.0  # –í—ã–ø–æ–ª–Ω—è–µ–º —Ç–æ–ª—å–∫–æ —Å–∏–ª—å–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã
            }
            
            signals.append(signal)
        
        return signals
    
    def save_models(self, filepath: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        if not ML_AVAILABLE or not self.is_trained:
            logger.warning("–ù–µ—Ç –º–æ–¥–µ–ª–µ–π –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return
        
        try:
            model_data = {
                'models': self.models,
                'scalers': self.scalers,
                'feature_columns': self.feature_columns,
                'is_trained': self.is_trained
            }
            
            joblib.dump(model_data, filepath)
            logger.info(f"–ú–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filepath}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
    
    def load_models(self, filepath: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        if not ML_AVAILABLE:
            logger.warning("ML –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
            return
        
        try:
            model_data = joblib.load(filepath)
            
            self.models = model_data['models']
            self.scalers = model_data['scalers']
            self.feature_columns = model_data['feature_columns']
            self.is_trained = model_data['is_trained']
            
            logger.info(f"–ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ {filepath}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}")

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
ml_prediction_service = MLPredictionService() 